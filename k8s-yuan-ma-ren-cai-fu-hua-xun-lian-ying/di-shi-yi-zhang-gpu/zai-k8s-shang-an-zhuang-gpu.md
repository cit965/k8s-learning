# åœ¨ k8s ä¸Šå®‰è£… gpu

**ç›®æ ‡å—ä¼—ï¼š** _Kubernetes æ“ä½œå‘˜ã€æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆã€GPU è¿· åŸæ–‡ ï¼š_[_https://www.jimangel.io/posts/nvidia-rtx-gpu-kubernetes-setup/_](https://www.jimangel.io/posts/nvidia-rtx-gpu-kubernetes-setup/)

æ¢ç´¢äº‘ä¸­ GPU çš„å¼ºå¤§åŠŸèƒ½æ¿€å‘äº†æˆ‘å°†æœ¬åœ° NVIDIA GPU ä¸æˆ‘çš„ Kubernetes å®¶åº­å®éªŒå®¤é›†ç¾¤é›†æˆçš„å…´è¶£ã€‚

å‘ Kubernetes æ·»åŠ  GPU ä½¿æˆ‘èƒ½å¤Ÿè¿è¡Œ Jupyter Notebooks å’Œ AI/ML å·¥ä½œè´Ÿè½½ã€‚è¿™ç§æ–¹æ³•çš„æœ€å¤§å¥½å¤„æ˜¯å¯ç§»æ¤æ€§ï¼›æœ¬åœ°è¿è¡Œçš„ç›¸åŒç¬”è®°æœ¬å’Œæ¨¡å‹å¯ä»¥è½»æ¾åœ¨äº‘ä¸­å¤åˆ¶ã€‚

è¿™ä¸ªä¸»é¢˜è®©æˆ‘æ„Ÿåˆ°å›°æƒ‘ï¼Œæˆ‘ä¸å¾—ä¸ä¾èµ–æ¥è‡ªå„ä¸ªä¾›åº”å•†çš„ä¿¡æ¯ã€GitHub é—®é¢˜å’Œå †æ ˆæº¢å‡ºå¸–å­ã€‚

æˆ‘çš„ç›®æ ‡æ˜¯æ­å¼€è¿™ä¸€è¿‡ç¨‹çš„ç¥ç§˜é¢çº±ï¼Œæä¾›ä¸€æ¡æ¸…æ™°çš„é€”å¾„ï¼Œè®©æ‚¨å¯ä»¥ç›´æ¥ä»è‡ªå·±çš„è®¾ç½®ä¸­åˆ©ç”¨ GPU åŠ é€Ÿæ¥å¤„ç† AI/ML å·¥ä½œè´Ÿè½½ã€‚

### &#x20;èŒƒå›´

å¦‚æœæ‚¨æ­£åœ¨å…³æ³¨ï¼š

* æ‚¨æœ‰ä¸€ä¸ªè¿è¡Œ Ubuntu 22.04 LTS çš„èŠ‚ç‚¹
* æ‚¨æœ‰ä¸€ä¸ªè¿æ¥åˆ°è¯¥èŠ‚ç‚¹çš„ NVIDIA GPU
* Kubernetes å®‰è£…å¹¶è¿è¡Œ

é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å‘½ä»¤éƒ½åº”åœ¨ä¸Šè¿°èŠ‚ç‚¹ä¸Šè¿è¡Œã€‚

### &#x20;ç»„ä»¶æ¦‚è§ˆ

è®©æˆ‘ä»¬å°† GPU è¿æ¥è·¯å¾„çš„æ¯ä¸ªæ­¥éª¤åˆ†è§£ä¸ºæ›´å¤§çš„ç»„ä»¶ï¼ˆ **pod/å·¥ä½œè´Ÿè½½**â†’ **kubernetes** â†’**å®¹å™¨è¿è¡Œæ—¶**â†’**è½¯ä»¶**â†’**ç¡¬ä»¶**â†’ **GPU** ï¼‰ã€‚

æˆ‘å°†ä»ä¸Šåˆ°ä¸‹ä»‹ç»æ¯ä¸ªç»„ä»¶ï¼Œç„¶åä½¿ç”¨â€œNEEDSâ€çš„ç›¸åé¡ºåºæ¥è®¾ç½®å’ŒéªŒè¯æˆ‘çš„ GPU åŠ é€Ÿçš„ Kubernetes homelabã€‚

ä¸‹å›¾ç›´è§‚åœ°å±•ç¤ºäº† Kubernetes è®¾ç½®ä¸­çš„ GPU è¿æ¥è·¯å¾„ï¼š

![](https://www.jimangel.io/img/gpu-stack-full.jpg)

ä»**pod/workload**å¼€å§‹ï¼Œå®¹å™¨åº”åŒ…å«è½¯ä»¶ï¼ˆå¦‚[CUDA](https://developer.nvidia.com/cuda-toolkit) ï¼‰ä»¥åˆ©ç”¨ GPU ç¡¬ä»¶ã€‚æˆ‘ä»¬å¯ä»¥å‡è®¾å®¹å™¨è‡ªåŠ¨è·å–å¸¦æœ‰é©±åŠ¨ç¨‹åºçš„ GPUï¼Œä½†æ‚¨ä»ç„¶éœ€è¦â€œåœ¨é¡¶éƒ¨â€æä¾› SDK/APIã€‚ NVIDIA**å®¹å™¨è¿è¡Œæ—¶**æŒ‚é’©æä¾›å®¹å™¨ GPU è®¾å¤‡é…ç½®ã€‚

#### Kubernetes å¦‚ä½•çŸ¥é“å“ªäº› Pod éœ€è¦ GPUï¼Ÿ

å¯¹äºæˆ‘çš„**Kubernetes**è®¾ç½®ï¼Œæˆ‘é€šè¿‡`spec.runtimeClassName` ï¼ˆ[è¿è¡Œæ—¶ç±»æ–‡æ¡£](https://kubernetes.io/docs/concepts/containers/runtime-class/)ï¼‰ã€ `spec.containers.resources` ï¼ˆ[èµ„æºé…é¢æ–‡æ¡£](https://kubernetes.io/docs/concepts/policy/resource-quotas/#resource-quota-for-extended-resources)ï¼‰å’Œ`spec.nodeSelector` ï¼ˆ [nodeSelector æ–‡æ¡£](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector)ï¼‰çš„ç»„åˆåœ¨ pod/å·¥ä½œè´Ÿè½½ä¸­å£°æ˜ GPUã€‚ä¾‹å¦‚ï¼š

```yaml
spec: runtimeClassName: nvidia #<--- USE THE NVIDIA CONTAINER RUNTIME containers: resources: limits: nvidia.com/gpu: 1 #<-- ASSIGN 1 GPU, IF MULTIPLE nodeSelector: #<--- RUN ON GPU ${NODE_NAME} kubernetes.io/hostname: ${NODE_NAME}
```

GPU èŠ‚ç‚¹ä¸Šå‡ºç°`NoSchedule`æ±¡ç‚¹ä¹Ÿå¾ˆå¸¸è§ã€‚è¿™æ˜¯ä¸ºäº†é˜²æ­¢ä¸æ˜ç¡®éœ€è¦ GPU çš„å·¥ä½œè´Ÿè½½è¿è¡Œï¼ˆ[æ±¡ç‚¹å’Œå®¹å¿æ–‡æ¡£](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)ï¼‰ã€‚å®¹å¿`NoSchedule`æ±¡æŸ“ï¼š

```yaml
spec: tolerations: - key: nvidia.com/gpu operator: Exists effect: NoSchedule
```

ä¸Šé¢çš„ YAML ç¤ºä¾‹æŒ‡ç¤º Kubernetes åœ¨ä½•å¤„/å¦‚ä½•è¿è¡Œå·¥ä½œè´Ÿè½½ï¼Œä½†æ˜¯ï¼ŒGPU è¢«è§†ä¸ºâ€œæ‰©å±•èµ„æºâ€æˆ–â€œé Kubernetes å†…ç½®èµ„æºâ€ï¼ˆ[æ–‡æ¡£](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#extended-resources)ï¼‰ã€‚\_å¿…é¡»\_æœ‰æŸç§ä¸œè¥¿å‘Šè¯‰ Kubernetes æœ‰ X ä¸ªèŠ‚ç‚¹å’Œ X ä¸ª GPU å¯ç”¨ã€‚

#### Kubernetes å¦‚ä½•çŸ¥é“å“ªäº›èŠ‚ç‚¹æœ‰ GPUï¼Ÿ

è®¸å¤š NVIDIA GPU åŠŸèƒ½å‡ç”±[NVIDIA GPU Operator](https://github.com/NVIDIA/gpu-operator)è‡ªåŠ¨ç®¡ç†ï¼ŒåŒ…æ‹¬å‘ Kubernetes é€šæŠ¥è®¾å¤‡å®¹é‡çš„`device-plugin-daemonset`éƒ¨ç½²ã€‚ ( [NVIDIA k8s-device-plugin æ–‡æ¡£](https://github.com/NVIDIA/k8s-device-plugin#quick-start))

![](https://www.jimangel.io/img/gpu-stack-k8s.jpg)

[NVIDIA GPU Operator](https://github.com/NVIDIA/gpu-operator)åŒ…æ‹¬ï¼š

* åœ¨ä¸»æœºä¸Šå®‰è£… NVIDIA é©±åŠ¨ç¨‹åºçš„ï¼ˆå¯é€‰ï¼‰èƒ½åŠ›
* é€‚ç”¨äº GPU çš„ Kubernetes è®¾å¤‡æ’ä»¶
* åœ¨ä¸»æœºä¸Šé…ç½® NVIDIA Container Runtime çš„ï¼ˆå¯é€‰ï¼‰èƒ½åŠ›
* &#x20;è‡ªåŠ¨èŠ‚ç‚¹æ ‡è®°
* åŸºäº DCGMï¼ˆæ•°æ®ä¸­å¿ƒ GPU ç®¡ç†å™¨ï¼‰çš„ç›‘æ§ç­‰

é‡è¦çš„éƒ¨åˆ†æ˜¯æ“ä½œå‘˜è‡ªåŠ¨ä¸ºé€‰æ‹©å™¨æ ‡è®°èŠ‚ç‚¹å¹¶è¯„ä¼°é…é¢å®¹é‡ã€‚

[NVIDIA è®¾å¤‡æ’ä»¶](https://github.com/NVIDIA/k8s-device-plugin)æ˜¯ä¸€ä¸ªå®ˆæŠ¤è¿›ç¨‹é›†ï¼Œå®ƒå…è®¸æ‚¨è‡ªåŠ¨ï¼š

* å…¬å¼€é›†ç¾¤æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„ GPU æ•°é‡
* è·Ÿè¸ª GPU çš„è¿è¡ŒçŠ¶å†µ
* åœ¨ Kubernetes é›†ç¾¤ä¸­è¿è¡Œæ”¯æŒ GPU çš„å®¹å™¨

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬çš„ Kubernetes é›†ç¾¤å·²å°†å·¥ä½œè´Ÿè½½è°ƒåº¦åˆ° GPU å°±ç»ªèŠ‚ç‚¹ï¼Œå¹¶å‘å®¹å™¨è¿è¡Œæ—¶æä¾›è¯·æ±‚ GPU åŠ é€Ÿçš„`nvidia` RuntimeClass çš„æŒ‡ä»¤ã€‚

#### `nvidia` runtimeClass å¦‚ä½•å…¬å¼€ GPUï¼Ÿ

åä¸º NVIDIA Container Toolkit ( [docs](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-containerd-for-nerdctl) ) çš„åŒ…æä¾›äº†å¤§éƒ¨åˆ†é…ç½®å’ŒäºŒè¿›åˆ¶æ–‡ä»¶ã€‚

åœ¨ GPU èŠ‚ç‚¹ä¸Šï¼Œ**å®¹å™¨è¿è¡Œæ—¶**(containerd) é…ç½®æœ‰ä¸€ä¸ªåä¸º`nvidia-container-runtime` ( [docs](https://github.com/NVIDIA/nvidia-container-toolkit/tree/main/cmd/nvidia-container-runtime) ) çš„`runc`åŒ…è£…å™¨ã€‚

![](https://www.jimangel.io/img/gpu-stack-containerd.jpg)

åŒ…è£…å™¨ ( `nvidia-container-runtime` ) ä½¿ç”¨`containerd`ä¸­çš„é¢„å¯åŠ¨æŒ‚é’©ï¼Œé€šè¿‡æŒ‚è½½ã€ç¯å¢ƒå˜é‡ç­‰æ·»åŠ ä¸»æœº GPUã€‚

å¯ä»¥å°†å…¶æƒ³è±¡ä¸ºå°† GPU ç¡¬ä»¶é…ç½®æ³¨å…¥åˆ°å®¹å™¨ä¸­ï¼Œä½†æ‚¨ä»ç„¶éœ€è¦æºå¸¦è½¯ä»¶ï¼ˆä¾‹å¦‚ CUDAï¼‰

ä»¥ä¸‹æ˜¯`containerd`ä½¿ç”¨ NVIDIA è¿è¡Œæ—¶ç±»çš„ç¤ºä¾‹é…ç½®ï¼š

```yaml
# /etc/containerd/config.toml [plugins."io.containerd.grpc.v1.cri".containerd.runtimes] [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia] privileged_without_host_devices = false runtime_engine = "" runtime_root = "" runtime_type = "io.containerd.runc.v2" [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia.options] BinaryName = "/usr/bin/nvidia-container-runtime"
```

åªè¦å®¹å™¨ä½¿ç”¨`nvidia`è¿è¡Œæ—¶ç±»ï¼Œå°±ä¼šä½¿ç”¨ä¸Šè¿°é…ç½®ã€‚

é…ç½®`/etc/containerd/config.toml`æ˜¯é€šè¿‡`nvidia-ctk` ï¼ˆ `nvidia-container-toolkit`çš„ä¸€ä¸ªå‘½åä¸ä½³çš„å­é›†å®ç”¨ç¨‹åºï¼‰è‡ªåŠ¨è¿›è¡Œçš„ï¼Œç¨åä»‹ç»ã€‚

`nvidia-container-toolkit`å’Œå®ç”¨ç¨‹åºè´Ÿè´£é…ç½®å®¹å™¨è¿è¡Œæ—¶ï¼Œä½†è¯¥è¿‡ç¨‹å‡è®¾æˆ‘ä»¬å·²ç»åœ¨ä¸»æœºä¸Šé…ç½®äº† GPUã€‚

#### Ubuntu å¦‚ä½•çŸ¥é“å®ƒæœ‰ GPUï¼Ÿ

ç®€çŸ­çš„ç­”æ¡ˆæ˜¯**å¸æœº**ã€‚é©±åŠ¨ç¨‹åºæ˜¯æ“ä½œç³»ç»Ÿä¸ NVIDIA æ˜¾å¡é€šä¿¡æ‰€éœ€çš„åŸºæœ¬è½¯ä»¶ã€‚

NVIDIA é©±åŠ¨ç¨‹åºä½¿ç”¨åŒ…ç®¡ç†å™¨å®‰è£…åœ¨ Ubuntu ä¸Šã€‚

NVIDIA é©±åŠ¨ç¨‹åºæœ‰ 2 ä¸ªéƒ¨åˆ†ï¼Œç¡¬ä»¶å¦‚ä½•çŸ¥é“å¦‚ä½•ä¸ GPU å¯¹è¯ï¼ˆ**ç¡¬ä»¶/å†…æ ¸**æ¨¡å—ï¼‰ä»¥åŠ**è½¯ä»¶**å¦‚ä½•çŸ¥é“å¦‚ä½•ä¸ GPU å¯¹è¯ã€‚

![](https://www.jimangel.io/img/gpu-stack-driver.jpg)

æˆ‘åœ¨å›¾ç‰‡ä¸­åŒ…å«äº†â€œCUDA stuffâ€ï¼Œå› ä¸ºå®ƒå¯ä»¥å®‰è£…åœ¨ä¸»æœºä¸Šï¼Œä½†è¿™å–å†³äºå…·ä½“çš„ç”¨ä¾‹ã€‚æœ¬æ¼”ç»ƒä¸éœ€è¦å®ƒï¼Œç¨åå°†å¯¹æ­¤è¿›è¡Œè®¨è®ºã€‚

#### ä¸»æ¿å¦‚ä½•çŸ¥é“ GPU å·²è¿æ¥ï¼Ÿ

è¿™æ˜¯ä¸€ä¸ªæœ‰ç‚¹æ£˜æ‰‹çš„é—®é¢˜ã€‚å¤§å¤šæ•°ï¼ˆå¦‚æœä¸æ˜¯å…¨éƒ¨ï¼‰æ¶ˆè´¹ç±» GPU éƒ½æ˜¯é€šè¿‡ PCIe è¿æ¥çš„ã€‚

![](https://www.jimangel.io/img/gpu-stack-pci.jpg)

å½“æˆ‘è¿›ä¸€æ­¥æ€è€ƒæ—¶ï¼ŒPCIe æ”¯æŒ GPUã€NVMeã€NIC å’Œè®¸å¤šå…¶ä»–å¤–è®¾ã€‚è¿™**åªæ˜¯ä¼ è¾“æ•°æ®çš„ä¸€ç§æ–¹å¼**ã€‚

ä¸»æ¿ä¸éœ€è¦çŸ¥é“å®ƒæ˜¯ GPUï¼Œä½†å®ƒç¡®å®éœ€è¦çŸ¥é“\_æœ‰ä»€ä¹ˆä¸œè¥¿\_é€šè¿‡ PCIe æ’å…¥äº†å®ƒã€‚

&#x20;ç¬”è®°

å¦‚æœä½¿ç”¨ Thunderbolt å¤–éƒ¨ GPU (eGPU)ï¼Œå®ƒä»ç„¶è¢«è§†ä¸º PCIã€‚ â€œThunderbolt å°† PCIe å’Œ DisplayPort ç»„åˆæˆä¸¤ä¸ªä¸²è¡Œä¿¡å·ï¼Œå¹¶é€šè¿‡å•æ ¹ç”µç¼†å¦å¤–æä¾›ç›´æµç”µæºã€‚â€ ï¼ˆ[æ¥æº](https://en.wikipedia.org/wiki/Thunderbolt\_\(interface\))ï¼‰

ç°åœ¨æˆ‘ä»¬ä½äºç»„ä»¶çš„åº•éƒ¨ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰ç…§ç›¸åçš„é¡ºåºåœ¨æœ¬åœ° Kubernetes é›†ç¾¤ä¸Šå®‰è£…å’ŒéªŒè¯ GPUã€‚

### åœ¨ Kubernetes ä¸Šé…ç½® NVIDIA RTX GPU

ä»æˆ‘ä»¬ä¸Šæ¬¡åœä¸‹çš„åœ°æ–¹å¼€å§‹ï¼Œè®©æˆ‘ä»¬æ£€æŸ¥ç‰©ç†ç¡¬ä»¶è¿æ¥ã€‚

#### éªŒè¯ç¡¬ä»¶è¿æ¥

ä½¿ç”¨`lspci`å®ç”¨ç¨‹åºï¼Œç”¨äºæ˜¾ç¤ºæœ‰å…³ç³»ç»Ÿä¸­çš„ PCI æ€»çº¿å’Œè¿æ¥åˆ°å®ƒä»¬çš„è®¾å¤‡çš„ä¿¡æ¯ï¼Œä»¥æŸ¥æ‰¾å·²çŸ¥çš„ NVIDIA è®¾å¤‡ã€‚

```bash
# list all PCI devices with the text NVIDIA sudo lspci | grep NVIDIA
```

&#x20;ä¸€åˆ‡éƒ½å¥½ï¼ âœ… è¾“å‡ºï¼š

```bash
2f:00.0 VGA compatible controller: NVIDIA Corporation GA106 [GeForce RTX 3060 Lite Hash Rate] (rev a1)
```

#### NVIDIA GPU é©±åŠ¨ç¨‹åºæ³¨æ„äº‹é¡¹

ä¸ä»…æœ‰è®¸å¤šç›¸äº’ç«äº‰çš„æ–¹æ³•æ¥å®‰è£…ç›¸åŒçš„ GPU é©±åŠ¨ç¨‹åºï¼Œè€Œä¸”æ‚¨å¦‚ä½•çŸ¥é“è¦ä½¿ç”¨å“ªä¸ªç‰ˆæœ¬ï¼Ÿ

**æŸ¥æ‰¾æ­£ç¡®çš„é©±åŠ¨ç¨‹åºç‰ˆæœ¬**

ä½¿ç”¨ NVIDIA ä¸Šçš„æœç´¢èœå•[é©±åŠ¨ç¨‹åºä¸‹è½½ç½‘ç«™](https://www.nvidia.com/download/index.aspx)æŸ¥æ‰¾è¦å®‰è£…çš„æœ€æ–°æ¨èç‰ˆæœ¬ã€‚

ä¾‹å¦‚ï¼Œæœç´¢ RTX 3060 å°†è¿”å›ï¼š

| åœºåœ°    | ä»·å€¼          |
| ----- | ----------- |
|  ç‰ˆæœ¬   | 535.154.05  |
|  å‘å¸ƒæ—¥æœŸ | 2024.1.16   |
|  æ“ä½œç³»ç»Ÿ |  Linux 64 ä½ |
|  è¯­è¨€   |  è‹±è¯­ï¼ˆç¾å›½ï¼‰     |
|  æ–‡ä»¶å¤§å° | 325.86 MB   |

è¿™æ„å‘³ç€æˆ‘æ­£åœ¨å¯»æ‰¾`535+` nvidia é©±åŠ¨ç¨‹åºç‰ˆæœ¬ã€‚

#### ï¼ˆå…³äº CUDA ç‰ˆæœ¬çš„æ—æ³¨ï¼‰

CUDA æ˜¯å¸®åŠ©åº”ç”¨ç¨‹åºåœ¨ NVIDIA GPU ä¸Šè¿è¡Œçš„é™„åŠ è½¯ä»¶ã€‚å°†å…¶è§†ä¸ºä¸»æœº GPU çš„ APIã€‚

è™½ç„¶\_æ­¤\_è®¾ç½®ä¸éœ€è¦ CUDA åŒ…ï¼Œä½†å®¹å™¨ä¸­ä½¿ç”¨çš„ CUDA å’Œé©±åŠ¨ç¨‹åºç‰ˆæœ¬ä¹‹é—´å­˜åœ¨åŠå¾®å¦™çš„å…³ç³»ã€‚å¦‚æœ CUDA å’Œæ‚¨çš„é©±åŠ¨ç¨‹åºä¹‹é—´ä¸åŒ¹é…ï¼Œäº‹æƒ…å¯èƒ½æ— æ³•æŒ‰é¢„æœŸå·¥ä½œï¼

&#x20;æç¤º

å®‰è£…é©±åŠ¨ç¨‹åºåï¼Œå¯ä»¥è¿è¡Œ`nvidia-smi`æ¥æ£€æŸ¥æ¨èçš„CUDAç‰ˆæœ¬ï¼Œä¾‹å¦‚nvidia-driver-535è¾“å‡ºCUDA `12.2`å³ä½¿æˆ‘æ²¡æœ‰å®‰è£…CUDAã€‚

ä¸€æ—¦æˆ‘ä¸**å®¹å™¨ä¸­çš„**CUDA ç‰ˆæœ¬ä»¥åŠåŒ¹é…çš„ä¸»æœºé©±åŠ¨ç¨‹åºä¿æŒä¸€è‡´ï¼Œæˆ‘çš„å¤§éƒ¨åˆ†é—®é¢˜å°±æ¶ˆå¤±äº†ã€‚ ï¼ˆ [CUDAä¸‹è½½](https://developer.nvidia.com/cuda-downloads)ï¼‰

å¦å¤–ï¼Œå…¬å¹³è­¦å‘Šï¼ŒCUDA ä¸ºæ‚¨çš„å®¹å™¨æ˜ åƒæ·»åŠ äº†å¤§é‡èµ„æºã€‚

å¦‚æœä½ å†³å¿ƒç¼©å°é•œåƒçš„å¤§å°ï¼Œå¯ä»¥é€‰æ‹©æ€§åœ° rm -rf Toolkit ä¸­ä¸éœ€è¦çš„éƒ¨åˆ†ï¼Œä½†è¦å°å¿ƒä¸è¦åˆ é™¤å®¹å™¨ä¸­åº”ç”¨ç¨‹åºå¯èƒ½ä½¿ç”¨çš„åº“å’Œå·¥å…·ï¼

#### å®‰è£… NVIDIA GPU é©±åŠ¨ç¨‹åº

åœ¨ Ubuntu 22.04 LTS ä¸Šå®‰è£… NVIDIA GPU é©±åŠ¨ç¨‹åºæœ‰å‡ ç§æµè¡Œçš„æ–¹æ³•ï¼š

* Ubuntu é€šè¿‡`ubuntu-drivers install`ç®¡ç† NVIDIA é©±åŠ¨ç¨‹åºï¼ˆ[æ–‡æ¡£](https://ubuntu.com/server/docs/nvidia-drivers-installation)ï¼‰
* NVIDIA é€šè¿‡`.run file`ç®¡ç† NVIDIA å®˜æ–¹é©±åŠ¨ç¨‹åºï¼ˆ[ä¸‹è½½](https://www.nvidia.com/download/index.aspx)ï¼‰
* éå®˜æ–¹ PPA ç®¡ç†çš„ NVIDIA é©±åŠ¨ç¨‹åºé€šè¿‡`ppa:graphics-drivers/ppa` ([æ–‡æ¡£](https://launchpad.net/\~graphics-drivers/+archive/ubuntu/ppa))

åœ¨æœ¬æ¼”ç»ƒä¸­ï¼Œæˆ‘ä½¿ç”¨æœ€åä¸€ä¸ªé€‰é¡¹ (ppa)ï¼Œä½†è¯·éšæ„æ›¿æ¢ä¸ºæ‚¨å–œæ¬¢çš„æ–¹æ³•ã€‚æˆ‘é€‰æ‹© PPA æ˜¯å› ä¸ºå®ƒçœ‹èµ·æ¥æœ€ç®€å•ã€‚

æ·»åŠ  PPA å­˜å‚¨åº“å¹¶å®‰è£…ä¸Šé¢æ‰¾åˆ°çš„é©±åŠ¨ç¨‹åºã€‚

```bash
# add ppa:graphics-driver repo to apt sudo add-apt-repository ppa:graphics-drivers/ppa --yes # update apt content list sudo apt update # install driver sudo apt install nvidia-driver-535
```

&#x20;è­¦å‘Š

æˆ‘é‡åˆ°äº†ä¸€ä¸ªé—®é¢˜ï¼ŒUbuntu çš„`unattended-upgrades`ä¼šè‡ªåŠ¨æ›´æ–°ä¸€äº› GPU é©±åŠ¨ç¨‹åºä¾èµ–é¡¹å¹¶ç ´åæˆ‘çš„ GPU é…ç½®ã€‚

å›ºå®šä¸º `sudo apt remove unattended-upgrades` ä½†è¿˜æœ‰å…¶ä»–ä¸å¤ªæœ‰åŠ›çš„è§£å†³æ–¹æ¡ˆã€‚

ç°åœ¨æˆ‘ä»¬å·²ç»å®‰è£…äº†é©±åŠ¨ç¨‹åºï¼Œè®©æˆ‘ä»¬éªŒè¯å®ƒä»¬æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚ä¸€ä¸ªå¿«é€Ÿæµ‹è¯•æ˜¯è¿è¡Œ`nvidia-smi` ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸º NVIDIA GPU æä¾›ç›‘æ§å’Œç®¡ç†åŠŸèƒ½çš„å®ç”¨ç¨‹åºã€‚

```bash
# get the driver version nvidia-smi --query-gpu=driver_version --format=csv,noheader
```

#### éªŒè¯ NVIDIA GPU é©±åŠ¨ç¨‹åº

é€šè¿‡åˆ—å‡ºåç§°ä¸­åŒ…å«â€œnvidiaâ€æˆ–â€œ535â€å®‰è£…çš„æ‰€æœ‰è½¯ä»¶åŒ… ( `dpkg -l` ) æ¥éªŒè¯å®‰è£…ã€‚

```bash
dpkg -l | grep nvidia # or dpkg -l | grep 535 # expected output: non-empty list of packages
```

&#x20;ä¸€åˆ‡éƒ½å¥½ï¼ âœ…

&#x20;æç¤º

ä¸ºäº†é˜²æ­¢æ„å¤–çš„è½¯ä»¶åŒ…æ›´æ”¹ï¼Œ `hold`å®ƒä»¬ä»¥é˜²æ­¢è‡ªåŠ¨å‡çº§ã€‚

```bash
# any package with nvidia in the name should be held dpkg-query -W --showformat='${Package} ${Status}\n' | \ grep -v deinstall | \ awk '{ print $1 }' | \ grep -E 'nvidia.*-[0-9]+$' | \ xargs -r -L 1 sudo apt-mark hold
```

&#x20;è¾“å‡ºï¼š

```bash
#... libnvidia-fbc1-535 set on hold. libnvidia-gl-535 set on hold. nvidia-compute-utils-535 set on hold. nvidia-dkms-535 set on hold.
```

è¿™ä¹Ÿæ„å‘³ç€ `sudo apt-mark unhold [package_name]` å¿…é¡»åœ¨å‡çº§ä¹‹å‰è¿è¡Œã€‚

**æ˜¯å¦å®‰è£…äº†å†…æ ¸æ¨¡å—ï¼Ÿå¸æœºåœ¨å·¥ä½œå—ï¼Ÿ**

æ¨¡å—æŒ‡ç¤ºå†…æ ¸å¦‚ä½•ä¸è¿æ¥åˆ°å®ƒçš„è®¾å¤‡è¿›è¡Œäº¤äº’ã€‚å¦‚æœæ²¡æœ‰ä»»ä½• NVIDIA æ¨¡å—ï¼Œæ“ä½œç³»ç»Ÿå°±ä¸çŸ¥é“å¦‚ä½•ä¸ç¡¬ä»¶é€šä¿¡ã€‚

ä½¿ç”¨`lsmod` ï¼Œè¯¥ç¨‹åºåˆ—å‡º`/proc/modules`çš„å†…å®¹ï¼Œæ˜¾ç¤ºå½“å‰åŠ è½½çš„å†…æ ¸æ¨¡å—ã€‚

```bash
# Show the status of driver modules in the Linux Kernel lsmod | grep nvidia
```

å¦‚æœæ‚¨å®‰è£…äº†æ¨¡å—ï¼Œå®ƒå¯èƒ½çœ‹èµ·æ¥åƒè¿™æ ·ï¼š

```bash
nvidia_uvm 1511424 12 nvidia_drm 77824 0 nvidia_modeset 1306624 1 nvidia_drm nvidia 56692736 200 nvidia_uvm,nvidia_modeset drm_kms_helper 311296 1 nvidia_drm drm 622592 4 drm_kms_helper,nvidia,nvidia_drm
```

&#x20;ç¬”è®°

æˆ‘æ­£åœ¨ä½¿ç”¨ eGPU æµ‹è¯•ä¸Šè¿°è¾“å‡ºï¼Œä½†æ¨¡å—æ²¡æœ‰æ˜¾ç¤ºã€‚æˆ‘ä»¥ä¸ºæˆ‘çš„ç†è§£é”™äº†ï¼Œç»“æœå‘ç°æˆ‘æ²¡æœ‰æ’çº¿ã€‚

è¿æ¥ eGPU è§£å†³äº†æˆ‘çš„é—®é¢˜å¹¶ä¸”æ¨¡å—å‡ºç°äº†ã€‚

æ£€æŸ¥å†…æ ¸é©±åŠ¨ç‰ˆæœ¬æ–‡ä»¶ï¼š

```bash
cat /proc/driver/nvidia/version
```

&#x20;ä¸€åˆ‡éƒ½å¥½ï¼ âœ… è¾“å‡ºï¼š

```bash
NVRM version: NVIDIA UNIX x86_64 Kernel Module 535.154.05 Thu Dec 28 15:37:48 UTC 2023 GCC version: gcc version 11.4.0 (Ubuntu 11.4.0-1ubuntu1~22.04)
```

æ£€æŸ¥è®¾å¤‡æ–‡ä»¶ä¸­æ‰¾åˆ°çš„ nvidia è®¾å¤‡ï¼š

```bash
# any device files (I/O sys calls) ls /dev/ | grep 'nvidia[0-9]\+'
```

&#x20;ä¸€åˆ‡éƒ½å¥½ï¼ âœ… è¾“å‡ºï¼š

çœ‹æ¥æˆ‘ä»¬æœ‰ä¸€ä¸ªå…·æœ‰å¯ç”¨ GPU è®¾ç½®çš„ä¸»æœºï¼Œæ¥ä¸‹æ¥è®©æˆ‘ä»¬é…ç½®`containerd`ä»¥æ”¯æŒ GPU è¿è¡Œæ—¶ã€‚

#### å®‰è£… NVIDIA å®¹å™¨å·¥å…·åŒ…

æˆ‘çš„å®¶åº­å®éªŒå®¤æ­£åœ¨ä½¿ç”¨`containerd`è¿è¡Œ Kubernetes v1.28.4ã€‚å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬éœ€è¦ NVIDIA Container Toolkitï¼ˆä¸€ç»„å®ç”¨ç¨‹åºï¼‰æ¥é…ç½®`containerd`ä»¥åˆ©ç”¨ NVIDIA GPUã€‚

æ®æˆ‘æ‰€çŸ¥ï¼Œè¿™ä¼šåœ¨æ‚¨çš„ä¸»æœºä¸Šå®‰è£…å·¥å…·ï¼Œä½†é»˜è®¤æƒ…å†µä¸‹ä¸ä¼šé…ç½®æˆ–æ›´æ”¹ä»»ä½•å†…å®¹ã€‚

æ¥è‡ªâ€œ[å®‰è£… NVIDIA å®¹å™¨å·¥å…·åŒ…](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)â€æŒ‡å—ã€‚

```bash
# add nvidia-container-toolkit repo to apt sources curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \ && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \ sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list # update apt content sudo apt update # install container toolkit sudo apt install -y nvidia-container-toolkit
```

#### é…ç½®`containerd`

ç°åœ¨å·¥å…·å·²å®‰è£…ï¼Œæˆ‘ä»¬éœ€è¦æ›´æ–°`containerd`é…ç½®è¿è¡Œæ—¶ç±»ã€‚å¹¸è¿çš„æ˜¯ï¼Œ `nvidia-ctk`æ˜¯å·¥å…·ä¹‹ä¸€ï¼Œå¯ä»¥è‡ªåŠ¨åŒ–è¯¥è¿‡ç¨‹ã€‚

æ¥è‡ªâ€œ[å®‰è£… NVIDIA å®¹å™¨å·¥å…·åŒ…](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuration)â€æŒ‡å—ã€‚

```bash
# options: --dry-run sudo nvidia-ctk runtime configure --runtime=containerd # restart containerd sudo systemctl restart containerd
```

éªŒè¯`containerd`æ˜¯å¦æ­£åœ¨è¿è¡Œ `sudo systemctl status containerd`

&#x20;ç¬”è®°

æ‚¨å¯ä»¥é€šè¿‡æŒ‡å®šè¿è¡Œæ—¶åç§° ( `--nvidia-runtime-name` )ã€NVIDIA è¿è¡Œæ—¶å¯æ‰§è¡Œæ–‡ä»¶çš„è·¯å¾„ ( `--nvidia-runtime-path` ) æ¥è‡ªå®šä¹‰ NVIDIA è¿è¡Œæ—¶é…ç½®`--nvidia-runtime-hook-path` ï¼‰ã€‚

è¿˜æœ‰ä¸€ä¸ªé€‰é¡¹å¯ä»¥ä½¿ç”¨`--nvidia-set-as-default`å°† NVIDIA è¿è¡Œæ—¶è®¾ç½®ä¸ºé»˜è®¤è¿è¡Œæ—¶ã€‚ ï¼ˆ[æ¥æº](https://github.com/NVIDIA/nvidia-container-toolkit/blob/main/cmd/nvidia-ctk/runtime/configure/configure.go)ï¼‰

å¦‚æœæ‚¨æƒ³æ·±å…¥äº†è§£`nvidia-container-runtime`åœ¨ä¸»æœºä¸Šå¦‚ä½•å…¬å¼€ GPUï¼Œæˆ‘å¼ºçƒˆå»ºè®®æ‚¨é˜…è¯»[æ–‡æ¡£](https://github.com/NVIDIA/nvidia-container-toolkit/tree/main/cmd/nvidia-container-runtime#usage-example)ä¸­çš„ä½çº§ç¤ºä¾‹ã€‚

å¦‚æœæ‚¨è¿˜æ²¡æœ‰åŒå€¦è¿™ä¸ªä¸»é¢˜ï¼Œé‚£ä¹ˆ NVIDIA çš„é¢˜ä¸ºâ€œ[åœ¨å®¹å™¨è¿è¡Œæ—¶ç”Ÿæ€ç³»ç»Ÿä¸­å¯ç”¨ GPU](https://developer.nvidia.com/blog/gpu-containers-runtime/) â€çš„åšå®¢éå¸¸æ£’ã€‚

#### éªŒè¯`containerd`

æ£€æŸ¥é…ç½®ä¸­æ˜¯å¦å­˜åœ¨ nvidia è¿è¡Œæ—¶ã€‚

```bash
sudo cat /etc/containerd/config.toml | grep "containerd.runtimes.nvidia."
```

&#x20;ä¸€åˆ‡éƒ½å¥½ï¼ âœ… è¾“å‡ºï¼š

```bash
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia] [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia.options]
```

è®©æˆ‘ä»¬å°è¯•ç›´æ¥åœ¨ä¸»æœºä¸Šè¿è¡Œå®¹å™¨ï¼ˆè·³è¿‡ Kubernetesï¼‰ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…`nerdctl` ï¼Œå®ƒæ˜¯`docker`çš„ç›´æ¥æ›¿ä»£å“ï¼Œå®ƒå…è®¸æˆ‘ä»¬ä½¿ç”¨`--gpus all`å‚æ•°ã€‚

å®‰è£… `nerdctl` ä½¿ç”¨é¢„ç¼–è¯‘ç‰ˆæœ¬ã€‚

è¯·æ³¨æ„æˆ‘é€‰æ‹©çš„ CUDA ç‰ˆæœ¬ï¼Œè¯·æŸ¥çœ‹å­˜å‚¨åº“ç½‘ç«™ä»¥è·å–æœ€æ–°çš„æ ‡ç­¾é€‰é¡¹ï¼š [docker.com/r/nvidia/cuda/tags](https://hub.docker.com/r/nvidia/cuda/tags)

```bash
# `nvidia-smi` command ran with cuda 12.3 sudo nerdctl run -it --rm --gpus all nvidia/cuda:12.3.1-base-ubuntu20.04 nvidia-smi # `nvcc -V` command ran with cuda 12.3 (the "12.3.1-base" image doesn't include nvcc) sudo nerdctl run -it --rm --gpus all nvidia/cuda:12.3.1-devel-ubuntu20.04 nvcc -V
```

&#x20;ä¸€åˆ‡éƒ½å¥½ï¼ âœ…

&#x20;ç¬”è®°

å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯å…·æœ‰å¤šä¸ª GPU çš„è®¡ç®—æœºï¼Œåˆ™å¯ä»¥å°†`--gpus all`æ›¿æ¢ä¸º`--gpus '"device=0,1"'`ä¹‹ç±»çš„å†…å®¹æ¥æµ‹è¯•å…±äº«å„ä¸ª GPUã€‚

```bash
# only use device 0 and 1 out of a possible [0,1,2,3] setup sudo nerdctl run -it --rm --gpus '"device=0,1"' nvidia/cuda:12.2.2-base-ubuntu22.04 nvidia-smi
```

æ­¤æ—¶ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªå¯ä»¥åœ¨å®¹å™¨è¿è¡Œæ—¶è¿è¡Œçš„ GPU èŠ‚ç‚¹ã€‚

#### ä½¿ç”¨`helm`å®‰è£… NVIDIA GPU Operator

æœ€åä¸€ä¸ªéš¾é¢˜æ˜¯ï¼Œæˆ‘ä»¬éœ€è¦è®© Kubernetes çŸ¥é“æˆ‘ä»¬æœ‰å¸¦æœ‰ GPU çš„èŠ‚ç‚¹ã€‚

[NVIIDA GPU Operator](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/getting-started.html)åœ¨ Kubernetes ä¸Šåˆ›å»º/é…ç½®/ç®¡ç† GPUï¼Œå¹¶é€šè¿‡ Helm Chart è¿›è¡Œå®‰è£…ã€‚

æŒ‰ç…§[å®˜æ–¹è¯´æ˜](https://helm.sh/docs/intro/install/)å®‰è£… helmã€‚å¦‚æœæ‚¨æœ‰å…´è¶£æŸ¥çœ‹ helm å›¾è¡¨å’Œå€¼[ï¼Œè¯·å‚é˜…æ­¤å¤„çš„ Github å­˜å‚¨åº“](https://github.com/NVIDIA/gpu-operator/tree/master/deployments/gpu-operator)ã€‚

&#x20;æ·»åŠ èˆµå­˜å‚¨åº“ï¼š

```bash
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia \ && helm repo update
```

åœ¨ Kubernetes é›†ç¾¤ä¸Šå®‰è£…è¯¥ç‰ˆæœ¬ã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼ŒOperator å°† NVIDIA Container Toolkit å’Œ NVIDIA é©±åŠ¨ç¨‹åºéƒ¨ç½²ä¸ºç³»ç»Ÿä¸Šçš„å®¹å™¨ã€‚ç”±äºæˆ‘ä»¬å·²ç»å®‰è£…äº†è¿™ä¸¤ä¸ªç»„ä»¶ï¼Œå› æ­¤æˆ‘ä»¬å°†è¿™äº›å€¼è®¾ç½®ä¸º`false` ã€‚

```bash
helm install --wait gpu-operator \ -n gpu-operator --create-namespace \ nvidia/gpu-operator \ --set driver.enabled=false \ --set toolkit.enabled=false
```

ç¡®ä¿æ‰€æœ‰ pod éƒ½æ­£å¸¸è¿è¡Œï¼š

```bash
# ensure nothing on kubernetes is wonky kubectl get pods -n gpu-operator | grep -i nvidia
```

&#x20;ä¸€åˆ‡éƒ½å¥½ï¼ âœ… è¾“å‡ºï¼š

```bash
nvidia-cuda-validator-4hh2v 0/1 Completed 0 3d20h nvidia-dcgm-exporter-86wcv 1/1 Running 5 (7d10h ago) 7d20h nvidia-device-plugin-daemonset-cxfnc 1/1 Running 0 26h nvidia-operator-validator-jhz6j 1/1 Running 0 3d20h
```

#### éªŒè¯ GPU è¿ç®—ç¬¦

```bash
kubectl -n gpu-operator logs deployment/gpu-operator | grep GPU
```

è¿™ä¸æ˜¯ä¸€ä¸ªä¸‡æ— ä¸€å¤±çš„æµ‹è¯•ï¼Œä½†ä½ åº”è¯¥çœ‹åˆ° `Number of nodes with GPU label","NodeCount": NUMBER_OF_EXPECTED_GPU_NODES` å…·æœ‰å®é™…å€¼ã€‚å¦‚æœæ˜¾ç¤º 0ï¼Œåˆ™å¯èƒ½å­˜åœ¨éœ€è¦è°ƒè¯•çš„é—®é¢˜ã€‚

æœ‰ç”¨çš„è°ƒè¯•å‘½ä»¤ï¼š `kubectl get events -n gpu-operator --sort-by='.lastTimestamp'`

&#x20;æç¤º

å½“æœ‰ç–‘é—®æ—¶ï¼ˆæˆ–è€…å½“ GPU æ“ä½œå‘˜ pod åœ¨å•ä¸ªèŠ‚ç‚¹ä¸Šé™·å…¥ init/ç»ˆæ­¢çŠ¶æ€ä½†åº•å±‚è®¾ç½®å®Œå¥½æ—¶ï¼‰ï¼šé‡æ–°å¯åŠ¨èŠ‚ç‚¹ã€‚

### &#x20;æŠŠå®ƒä»¬æ”¾åœ¨ä¸€èµ·

æœ€åï¼Œè®©æˆ‘ä»¬è¿è¡Œ Kubernetes å·¥ä½œè´Ÿè½½æ¥æµ‹è¯•æˆ‘ä»¬çš„é›†æˆæ˜¯å¦å¯ä»¥ç«¯åˆ°ç«¯è¿è¡Œã€‚

```bash
# EXPORT NODE NAME! export NODE_NAME=node3 cat <<EOF | kubectl create -f - apiVersion: batch/v1 kind: Job metadata: name: test-job-gpu spec: template: spec: runtimeClassName: nvidia containers: - name: nvidia-test image: nvidia/cuda:12.0.0-base-ubuntu22.04 command: ["nvidia-smi"] resources: limits: nvidia.com/gpu: 1 nodeSelector: kubernetes.io/hostname: ${NODE_NAME} restartPolicy: Never EOF
```

é€šè¿‡`logs`æ£€æŸ¥è¾“å‡ºï¼š

```bash
kubectl logs job/test-job-gpu
```

é¢„æœŸè¾“å‡ºç±»ä¼¼äºï¼š

![](https://www.jimangel.io/img/gpu-smi.jpeg)

æ­å–œï¼ ğŸ‰ğŸ‰ğŸ‰ æˆ‘ä»¬æ­£å¼æ‹¥æœ‰æœ¬åœ° GPU åŠ é€Ÿçš„ Kubernetes é›†ç¾¤ï¼

### &#x20;ç»“è®º

ç”±äºæ¶‰åŠçš„æŠ€æœ¯å±‚ï¼Œå°† GPU é›†æˆåˆ° Kubernetes ä¸­å¯èƒ½çœ‹èµ·æ¥ä»¤äººç•æƒ§ã€‚æˆ‘å¸Œæœ›æœ¬æŒ‡å—èƒ½å¤Ÿä¸ºæ‚¨æ­å¼€ NVIDIA GPU ä¸ Kubernetes é›†æˆè¿‡ç¨‹çš„ç¥ç§˜é¢çº±ã€‚

æ€»è€Œè¨€ä¹‹ï¼Œåœ¨ k8s ä¸Šæš´éœ² GPU åŒ…æ‹¬ï¼š

1. å®‰è£… NVIDIA GPU é©±åŠ¨ç¨‹åº ( `apt install nvidia-driver-535` )
2. é…ç½®å®¹å™¨è¿è¡Œæ—¶ï¼ˆ `apt install -y nvidia-container-toolkit` & `nvidia-ctk runtime configure` ï¼‰
3. é…ç½® kubernetes ( `helm install nvidia/gpu-operator` ï¼‰
4. æ›´æ–°éƒ¨ç½² YAML ä»¥åŒ…å« GPU è¯·æ±‚

å°†æ¥ï¼Œæˆ‘ä¼šè€ƒè™‘ä½¿ç”¨`ubuntu-driver`å®‰è£…ç¨‹åºå’Œ/æˆ–è®© Kubernetes GPU Operator ç®¡ç†é©±åŠ¨ç¨‹åºå’Œå®¹å™¨å·¥å…·åŒ…ã€‚

å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜ã€è§è§£æˆ–åé¦ˆï¼Œè¯·éšæ—¶åˆ†äº«ï¼

### &#x20;æ¸…ç†

æƒ³é‡æ–°å¼€å§‹å—ï¼Ÿå®‰è£…ä¸åŒçš„é©±åŠ¨ç¨‹åºï¼Ÿåˆ é™¤æ‰€æœ‰å†…å®¹ï¼š

```bash
# drain node / remove from cluster # remove gpu-operator deployment helm -n gpu-operator list helm -n gpu-operator delete HELM_RELEASE_NAME # delete driver packages sudo apt remove --purge '^nvidia-.*' sudo apt remove --purge '^libnvidia-.*' # clean up the uninstall sudo apt autoremove # restart containerd
```

### å¥–åŠ±ï¼šæ‡’æƒ°çš„ GKE A100 æ¢ç´¢

æˆ‘å¾ˆå¥½å¥‡æˆ‘ç›®å‰å¯¹æœ¬åœ° NVIDIA GPU çš„ç†è§£ä¸äº‘ä¸­çš„ GPU åŠ é€Ÿç›¸æ¯”å¦‚ä½•ï¼Œå› æ­¤æˆ‘åœ¨ GKE ä¸Šå¯åŠ¨äº†ä¸€ä¸ª A100 èŠ‚ç‚¹ã€‚

æˆ‘å¿…é¡»éƒ¨ç½²è¯¥èŠ‚ç‚¹ä¸¤æ¬¡ï¼Œå› ä¸ºæˆ‘åœ¨ç¬¬ä¸€æ¬¡éƒ¨ç½²æ—¶çŠ¯äº†ä¸€ä¸ªé”™è¯¯ã€‚æˆ‘çœç•¥äº†`gpu-driver-version=default` ï¼›æ‰€ä»¥æ²¡æœ‰æ‰¾åˆ°é©±åŠ¨ç¨‹åºå’Œå·¥å…·ï¼ˆæŒ‰é¢„æœŸï¼‰ï¼Œä½†æˆ‘å¯ä»¥çœ‹åˆ°è¿æ¥çš„ PCI è®¾å¤‡ã€‚

[è¿™é‡Œæœ‰å…³äºåœ¨ COS ä¸Šæ‰‹åŠ¨å®‰è£…é©±åŠ¨ç¨‹åº](https://github.com/GoogleCloudPlatform/container-engine-accelerators/blob/master/cmd/nvidia\_gpu/README.md)çš„è¯´æ˜ï¼Œä½†æˆ‘è®¤ä¸ºå®ƒè¶…å‡ºäº†èŒƒå›´ã€‚

è¿™æ˜¯æˆ‘ç”¨æ¥ï¼ˆé‡æ–°ï¼‰åˆ›å»ºèŠ‚ç‚¹æ± çš„å‘½ä»¤ï¼š

```bash
# create command gcloud container node-pools create gpu-pool-2 \ --cluster cluster-2 \ --region us-central1 \ --machine-type a2-highgpu-1g \ --num-nodes 1 \ --accelerator type=nvidia-tesla-a100,count=1,gpu-driver-version=default
```

è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬èƒ½æ‰¾åˆ°ä»€ä¹ˆï¼

```bash
# gcloud compute ssh NODE_NAME # PCI connection? sudo lspci | grep NVIDIA 00:04.0 3D controller: NVIDIA Corporation GA100 [A100 SXM4 40GB] (rev a1) # Driver installed? cat /proc/driver/nvidia/version #NVRM version: NVIDIA UNIX x86_64 Kernel Module 470.223.02 Sat Oct 7 15:39:11 UTC 2023 #GCC version: Selected multilib: .;@m64 # tab complete `nvidia-c*` nvidia-container-runtime nvidia-container-runtime.cdi nvidia-container-runtime-hook nvidia-ctk # Where is nvidia-smi? sudo find / -type f -name "nvidia-smi" 2>/dev/null # /home/kubernetes/bin/nvidia/bin/nvidia-smi # Runtime? sudo cat /etc/containerd/config.toml | grep "containerd.runtimes.nvidia." # NO! # But, a quick look around: # bin k8s container runtime is in the default + device plugin # it looks like some things mounted via default runc runtime here, but idk sudo cat /etc/containerd/config.toml | grep bin # OUTPUT # bin_dir = "/home/kubernetes/bin" # ls /home/kubernetes/bin/nvidia/bin/ #nvidia-bug-report.sh nvidia-debugdump nvidia-ngx-updater nvidia-sleep.sh nvidia-xconfig #nvidia-cuda-mps-control nvidia-installer nvidia-persistenced nvidia-smi #nvidia-cuda-mps-server nvidia-modprobe nvidia-settings nvidia-uninstall # check nvidia containers running crictl ps | grep nvidia-gpu # OUTPUT 25eec6551f9e5 2f78042af231d 7 hours ago Running nvidia-gpu-device-plugin 0 ca9dd0d8e2822 nvidia-gpu-device-plugin-small-cos-674fk
```

å‡‰çˆ½çš„ï¼æœ‰äº›äº‹æƒ…æ˜¯æˆ‘å‡è®¾çš„ï¼Œæœ‰äº›äº‹æƒ…æˆ‘è¿˜éœ€è¦è¿›ä¸€æ­¥æŒ–æ˜ï¼
